{"cells":[{"cell_type":"markdown","source":"## Gradient boosting with XGBoost\n\nScope:\n- I'm going to train a gradient boosting model on the same diabetes dataset I used in the linear regression example. I'm going to compare the performance with the baseline model.","metadata":{"tags":[],"cell_id":"00000-0fea0107-615f-4549-bd1c-66aacdca793d"}},{"cell_type":"code","metadata":{"execution_millis":1,"execution_start":1604179960955,"output_cleared":false,"source_hash":"b6715547","tags":[],"cell_id":"00001-832a10f5-bdd5-4654-bd3a-bf6a813cae62"},"source":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport pandas as pd\nimport altair as alt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"execution_millis":0,"execution_start":1604178778547,"output_cleared":false,"source_hash":"5e3b34ed","tags":[],"cell_id":"00002-8aa9d945-d29d-408f-9e68-81f9f2e1b80d"},"source":"diabetes_df = pd.read_csv('../data/diabetes.csv')\n\n# I want the column names to be a bit more descriptive\ndiabetes_df.rename(columns={'S1':'t_cells', 'S2':'ld_lipo', 'S3':'hd_lipo',\n                            'S4':'thyroid_sh', 'S5':'lamotrigine', 'S6':'blood_sugar'}, inplace=True)\n\ndiabetes_df.columns = [col.lower() for col in diabetes_df]","execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Let's see what this dataset looks like.","metadata":{"tags":[],"cell_id":"00003-9649d698-e69e-490b-8023-6c0786c7f9dc"}},{"cell_type":"code","metadata":{"execution_millis":3,"execution_start":1604178830245,"output_cleared":false,"source_hash":"f618742","tags":[],"cell_id":"00004-3cae615a-8110-4708-8802-054a72e40941"},"source":"diabetes_df.info()","execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 442 entries, 0 to 441\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   age          442 non-null    int64  \n 1   sex          442 non-null    int64  \n 2   bmi          442 non-null    float64\n 3   bp           442 non-null    float64\n 4   t_cells      442 non-null    int64  \n 5   ld_lipo      442 non-null    float64\n 6   hd_lipo      442 non-null    float64\n 7   thyroid-sh   442 non-null    float64\n 8   lamotrigine  442 non-null    float64\n 9   blood_sugar  442 non-null    int64  \n 10  y            442 non-null    int64  \ndtypes: float64(6), int64(5)\nmemory usage: 38.1 KB\n"}]},{"cell_type":"markdown","source":"We have no null values, which is great. We have 10 features or predictive variables and one target variable, Y. Y is a quantitative measure of disease progression one year after baseline. But what does Y actually look like?","metadata":{"tags":[],"cell_id":"00005-0a390619-e0b6-4b5e-82f3-d6da45357842"}},{"cell_type":"code","metadata":{"execution_millis":23,"execution_start":1604178896073,"output_cleared":false,"source_hash":"eecfbfe9","tags":[],"cell_id":"00006-10065bfe-7aa8-4b11-826b-771a7f537e64"},"source":"diabetes_df.describe()['y']","execution_count":6,"outputs":[{"data":{"text/plain":"count    442.000000\nmean     152.133484\nstd       77.093005\nmin       25.000000\n25%       87.000000\n50%      140.500000\n75%      211.500000\nmax      346.000000\nName: y, dtype: float64"},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"cell_id":"00007-61717ca5-a08e-405d-b20f-4ddfe223192b"},"source":"diabetes_df = diabetes_df.drop('ld_lipo', axis=1)\ndiabetes_df = diabetes_df.drop('thyroid_sh', axis=1)","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"execution_millis":3,"execution_start":1604180008595,"output_cleared":false,"source_hash":"91156ab0","tags":[],"cell_id":"00008-6624d719-fa3a-4c2b-9ff5-11468df1cd60"},"source":"# let's eliminate the predicted column, then split the data\nX = diabetes_df.drop('y', axis=1)\ny = diabetes_df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=True)","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00009-3fca39a1-0abc-48bd-9d3f-49db4b5cf26f"},"source":"def run_booster(learning_rate):\n    bst = XGBRegressor(n_estimators=1000, learning_rate=learning_rate) # initialising using scikit API\n    bst.fit(X_train, y_train,\n            eval_set=[(X_test, y_test)],\n            early_stopping_rounds=5,\n            verbose=False)\n\n    # predicting the test data\n    return bst.predict(X_test)","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution_millis":3,"execution_start":1604180133395,"output_cleared":false,"source_hash":"e33ec73","tags":[],"cell_id":"00010-517bfe88-6912-4b00-94a6-4e74514d01c1"},"source":"# testing 7 values for the learning rate, equally spaced between 0.001 and 1\n\nresults = []\nalpha_range = np.linspace(0.001, 1, num=50)\nfor alpha in alpha_range:\n    predictions_bst = run_booster(alpha)\n    results.append([alpha, \n                    mean_absolute_error(y_test, predictions_bst), \n                    round(r2_score(y_test, predictions_bst),2)])\n    \ncolumn_names = ['learning_rate', 'mean_absolute_error', 'r2_score']\nres_df = pd.DataFrame(results, columns=column_names).set_index('learning_rate')\nres_df.sort_values(by='r2_score', ascending=False)","execution_count":13,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_absolute_error</th>\n      <th>r2_score</th>\n    </tr>\n    <tr>\n      <th>learning_rate</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.367980</th>\n      <td>42.290773</td>\n      <td>0.57</td>\n    </tr>\n    <tr>\n      <th>0.551469</th>\n      <td>43.561084</td>\n      <td>0.56</td>\n    </tr>\n    <tr>\n      <th>0.510694</th>\n      <td>43.330521</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>0.347592</th>\n      <td>44.946175</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>0.143714</th>\n      <td>44.028810</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>0.164102</th>\n      <td>44.223291</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>0.184490</th>\n      <td>43.655887</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>0.082551</th>\n      <td>44.674120</td>\n      <td>0.52</td>\n    </tr>\n    <tr>\n      <th>0.204878</th>\n      <td>43.369208</td>\n      <td>0.52</td>\n    </tr>\n    <tr>\n      <th>0.286429</th>\n      <td>45.543297</td>\n      <td>0.51</td>\n    </tr>\n    <tr>\n      <th>0.531082</th>\n      <td>44.787639</td>\n      <td>0.51</td>\n    </tr>\n    <tr>\n      <th>0.306816</th>\n      <td>44.283662</td>\n      <td>0.51</td>\n    </tr>\n    <tr>\n      <th>0.123327</th>\n      <td>45.251737</td>\n      <td>0.51</td>\n    </tr>\n    <tr>\n      <th>0.021388</th>\n      <td>46.291306</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>0.225265</th>\n      <td>45.160350</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>0.041776</th>\n      <td>46.349000</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>0.062163</th>\n      <td>46.253783</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>0.429143</th>\n      <td>45.838009</td>\n      <td>0.49</td>\n    </tr>\n    <tr>\n      <th>0.653408</th>\n      <td>46.092170</td>\n      <td>0.49</td>\n    </tr>\n    <tr>\n      <th>0.327204</th>\n      <td>45.497372</td>\n      <td>0.49</td>\n    </tr>\n    <tr>\n      <th>0.734959</th>\n      <td>45.587885</td>\n      <td>0.49</td>\n    </tr>\n    <tr>\n      <th>0.245653</th>\n      <td>46.593013</td>\n      <td>0.48</td>\n    </tr>\n    <tr>\n      <th>0.388367</th>\n      <td>47.553135</td>\n      <td>0.48</td>\n    </tr>\n    <tr>\n      <th>0.102939</th>\n      <td>47.260436</td>\n      <td>0.48</td>\n    </tr>\n    <tr>\n      <th>0.673796</th>\n      <td>47.090960</td>\n      <td>0.48</td>\n    </tr>\n    <tr>\n      <th>0.266041</th>\n      <td>47.009933</td>\n      <td>0.47</td>\n    </tr>\n    <tr>\n      <th>0.571857</th>\n      <td>45.630806</td>\n      <td>0.47</td>\n    </tr>\n    <tr>\n      <th>0.592245</th>\n      <td>46.210875</td>\n      <td>0.47</td>\n    </tr>\n    <tr>\n      <th>0.714571</th>\n      <td>46.898633</td>\n      <td>0.46</td>\n    </tr>\n    <tr>\n      <th>0.469918</th>\n      <td>48.551104</td>\n      <td>0.46</td>\n    </tr>\n    <tr>\n      <th>0.694184</th>\n      <td>46.115376</td>\n      <td>0.46</td>\n    </tr>\n    <tr>\n      <th>1.000000</th>\n      <td>46.344125</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>0.633020</th>\n      <td>46.263593</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>0.490306</th>\n      <td>47.648194</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>0.449531</th>\n      <td>47.592282</td>\n      <td>0.44</td>\n    </tr>\n    <tr>\n      <th>0.408755</th>\n      <td>48.636235</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>0.612633</th>\n      <td>47.099959</td>\n      <td>0.42</td>\n    </tr>\n    <tr>\n      <th>0.755347</th>\n      <td>48.320358</td>\n      <td>0.40</td>\n    </tr>\n    <tr>\n      <th>0.775735</th>\n      <td>49.686877</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>0.816510</th>\n      <td>51.407651</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>0.979612</th>\n      <td>50.793315</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>0.959224</th>\n      <td>50.579056</td>\n      <td>0.34</td>\n    </tr>\n    <tr>\n      <th>0.938837</th>\n      <td>50.619274</td>\n      <td>0.34</td>\n    </tr>\n    <tr>\n      <th>0.918449</th>\n      <td>50.865052</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>0.836898</th>\n      <td>50.373222</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>0.898061</th>\n      <td>51.179194</td>\n      <td>0.31</td>\n    </tr>\n    <tr>\n      <th>0.857286</th>\n      <td>51.043785</td>\n      <td>0.30</td>\n    </tr>\n    <tr>\n      <th>0.796122</th>\n      <td>54.016088</td>\n      <td>0.30</td>\n    </tr>\n    <tr>\n      <th>0.877673</th>\n      <td>51.584656</td>\n      <td>0.29</td>\n    </tr>\n    <tr>\n      <th>0.001000</th>\n      <td>60.655081</td>\n      <td>-0.04</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"               mean_absolute_error  r2_score\nlearning_rate                               \n0.367980                 42.290773      0.57\n0.551469                 43.561084      0.56\n0.510694                 43.330521      0.53\n0.347592                 44.946175      0.53\n0.143714                 44.028810      0.53\n0.164102                 44.223291      0.53\n0.184490                 43.655887      0.53\n0.082551                 44.674120      0.52\n0.204878                 43.369208      0.52\n0.286429                 45.543297      0.51\n0.531082                 44.787639      0.51\n0.306816                 44.283662      0.51\n0.123327                 45.251737      0.51\n0.021388                 46.291306      0.50\n0.225265                 45.160350      0.50\n0.041776                 46.349000      0.50\n0.062163                 46.253783      0.50\n0.429143                 45.838009      0.49\n0.653408                 46.092170      0.49\n0.327204                 45.497372      0.49\n0.734959                 45.587885      0.49\n0.245653                 46.593013      0.48\n0.388367                 47.553135      0.48\n0.102939                 47.260436      0.48\n0.673796                 47.090960      0.48\n0.266041                 47.009933      0.47\n0.571857                 45.630806      0.47\n0.592245                 46.210875      0.47\n0.714571                 46.898633      0.46\n0.469918                 48.551104      0.46\n0.694184                 46.115376      0.46\n1.000000                 46.344125      0.45\n0.633020                 46.263593      0.45\n0.490306                 47.648194      0.45\n0.449531                 47.592282      0.44\n0.408755                 48.636235      0.43\n0.612633                 47.099959      0.42\n0.755347                 48.320358      0.40\n0.775735                 49.686877      0.36\n0.816510                 51.407651      0.36\n0.979612                 50.793315      0.35\n0.959224                 50.579056      0.34\n0.938837                 50.619274      0.34\n0.918449                 50.865052      0.33\n0.836898                 50.373222      0.33\n0.898061                 51.179194      0.31\n0.857286                 51.043785      0.30\n0.796122                 54.016088      0.30\n0.877673                 51.584656      0.29\n0.001000                 60.655081     -0.04"},"execution_count":13,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","source":"It doesn't look like the gradient boosting is working very well. Our top score is 0.53.","metadata":{"cell_id":"00011-30676c0a-2699-4299-a2f7-ef59cc4e0773"}},{"cell_type":"code","metadata":{"allow_embed":true,"execution_millis":59,"execution_start":1604182060731,"output_cleared":false,"source_hash":"7dcdfe7f","tags":[],"cell_id":"00012-0c371188-ffa1-4a7a-ae81-bfdbb4b99929"},"source":"# just playing around with different visualisations\n# what would be useful to visualise?\ndef plot_altair(column):\n    return alt.Chart(diabetes_df).mark_point(filled=True).encode(\n        x = alt.X(column, scale=alt.Scale(zero=False)),\n        y = alt.Y('y:Q', scale=alt.Scale(zero=False)))\n        # color = alt.Color('SEX:N'),\n        # size = alt.Size('blood_sugar:Q', title='Blood sugar'),\n        # opacity = alt.OpacityValue(0.5))\n\n# a regression line for each variable against the target variable\n# but this is the /actual/ target variable, not the model's prediction of it\ncharts = []\nfor col in list(X.columns):\n    chart = plot_altair(col + ':Q')\n    charts.append(chart + chart.transform_regression(str(col), 'Y').mark_line())\n\nalt.vconcat(*charts[2:])","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00013-7fc1cf71-1f13-43c7-a7d6-40ceee15fdfe"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":4,"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"2e872e7b-11ac-4fc2-8fa4-34d3a2f81e80","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}}}