{"cells":[{"cell_type":"markdown","source":"# scikit-learn\n---\nThis is the getting started at [scikit-learn.org](https://scikit-learn.org/stable/getting_started.html).","metadata":{"tags":[],"cell_id":"00002-3506f793-4a9b-46ef-8516-d8082fd569fb"}},{"cell_type":"markdown","source":"sklearn calls its built-in algorithms and models estimators. They all inherit the same class `BaseEstimator`. Here's an example, a random forest classifier:","metadata":{"tags":[],"cell_id":"00001-06aada0f-0e6f-4e99-a57d-cdd1d1516138"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-bf2ff717-25aa-4c4b-a1e5-021c4cee2ab6","output_cleared":false,"source_hash":"7901d0c1","execution_millis":190,"execution_start":1603917857978},"source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(random_state=0)\n\nX = [[1, 2, 3], [11, 12, 13]]\ny = [0, 1]\nclf.fit(X, y)\n\nclf.predict([[4,5,6], [14,15,16]])","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"array([0, 1])"},"metadata":{}}]},{"cell_type":"markdown","source":"This is a transformer—a set of steps that pre-process and impute the data.","metadata":{"tags":[],"cell_id":"00004-ad24d3bb-bd10-4377-9733-45467b6b79dd"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00003-1ae44a4f-1919-4f94-a882-8b6163076dfc","output_cleared":false,"source_hash":"3d2388ff","execution_start":1603916631389,"execution_millis":3},"source":"from sklearn.preprocessing import StandardScaler\nX = [[0,15],[1, -10]]\nStandardScaler().fit(X).transform(X)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"array([[-1.,  1.],\n       [ 1., -1.]])"},"metadata":{}}]},{"cell_type":"markdown","source":"This is pretty cool: it's creating a pipeline made up of a transformer (it cleans the data) and the estimator itself—in this case logistic regression. When you fit the model to the data, it automatically runs the transformer first, then fits the estimator.","metadata":{"tags":[],"cell_id":"00006-09200df5-b741-414f-afd9-a82d0611ee61"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-8876cb30-4a60-4115-a191-56ee8a5838ca","output_cleared":false,"source_hash":"f3fdfdbf","execution_start":1603917607852,"execution_millis":57},"source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\npipe = make_pipeline(\n    StandardScaler(),\n    LogisticRegression(random_state=0)\n)\n\nX, y = load_iris(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\npipe.fit(X_train, y_train)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"Pipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression(random_state=0))])"},"metadata":{}}]},{"cell_type":"markdown","source":"We can then evaluate this model using the imported `accuracy_score`:","metadata":{"tags":[],"cell_id":"00007-42dd11e2-e65e-4103-9266-683e2d4c7323"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00005-7c15e872-98c2-45ab-9596-68ad19eced2b","output_cleared":false,"source_hash":"e42f493a","execution_start":1603917648014,"execution_millis":0},"source":"accuracy_score(pipe.predict(X_test), y_test)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"0.9736842105263158"},"metadata":{}}]},{"cell_type":"markdown","source":"sklearn has a bunch of tools to evaluate your model, including cross-validation. My model of it right now is a way of splitting the training and test data in such a way that it helps your model learn better. I don't have a formal definition.","metadata":{"tags":[],"cell_id":"00009-ef52ba5f-bb47-4796-86c5-930f78663330"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00010-b8cb307a-b6f8-46d4-951f-f35e5392f15a","output_cleared":false,"source_hash":"45868a3a","execution_millis":538,"execution_start":1603919275678},"source":"from sklearn.datasets import make_regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_validate\n\nX, y = make_regression(n_samples=1000, random_state=0) # this is cool! it generates a random regression problem\nlr = LinearRegression()\n\nresult = cross_validate(lr, X, y)\nresult['test_score']","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"array([1., 1., 1., 1., 1.])"},"metadata":{}}]},{"cell_type":"markdown","source":"Estimators have parameters—called hyper-parameters—that you can tune. It's not clear beforehand what these should be, since they depend on the data you're working with. sklearn has tools to find the best parameter combination.","metadata":{"tags":[],"cell_id":"00011-85da78fe-24cf-4544-ba8d-7735d15768e7"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00012-22ec8204-1bbe-4060-803c-0f076d76f6f1","output_cleared":false,"source_hash":"eaafcbe5","execution_millis":3795,"execution_start":1603920273489},"source":"from sklearn.datasets import fetch_california_housing\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import randint\n\nX, y = fetch_california_housing(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nparam_distributions = {'n_estimators': randint(1, 5),\n                        'max_depth': randint(5, 10)}\n                \nsearch = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n                            n_iter=5,\n                            param_distributions=param_distributions,\n                            random_state=0)\n\nsearch.fit(X_train, y_train)\n\nsearch.best_params_","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"{'max_depth': 9, 'n_estimators': 4}"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00013-c55dd4ea-a696-487e-a305-37c4aef606a9","output_cleared":false,"source_hash":"ab2a03e2","execution_millis":45,"execution_start":1603920279426},"source":"search.score(X_test, y_test)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"0.735363411343253"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00014-5efc0336-9c59-40e9-9cbb-d559cb8a2ac3"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"ab8f9f56-065b-4daa-a5ab-ee7a0763289e","deepnote_execution_queue":[]}}