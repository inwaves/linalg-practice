{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-3506f793-4a9b-46ef-8516-d8082fd569fb",
    "tags": []
   },
   "source": [
    "# scikit-learn\n",
    "---\n",
    "This is the getting started at [scikit-learn.org](https://scikit-learn.org/stable/getting_started.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-06aada0f-0e6f-4e99-a57d-cdd1d1516138",
    "tags": []
   },
   "source": [
    "sklearn calls its built-in algorithms and models estimators. They all inherit the same class `BaseEstimator`. Here's an example, a random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00000-bf2ff717-25aa-4c4b-a1e5-021c4cee2ab6",
    "execution_millis": 190,
    "execution_start": 1603917857978,
    "output_cleared": false,
    "source_hash": "7901d0c1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "X = [[1, 2, 3], [11, 12, 13]]\n",
    "y = [0, 1]\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.predict([[4,5,6], [14,15,16]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-ad24d3bb-bd10-4377-9733-45467b6b79dd",
    "tags": []
   },
   "source": [
    "This is a transformer—a set of steps that pre-process and impute the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00003-1ae44a4f-1919-4f94-a882-8b6163076dfc",
    "execution_millis": 3,
    "execution_start": 1603916631389,
    "output_cleared": false,
    "source_hash": "3d2388ff",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.],\n",
       "       [ 1., -1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = [[0,15],[1, -10]]\n",
    "StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-09200df5-b741-414f-afd9-a82d0611ee61",
    "tags": []
   },
   "source": [
    "This is pretty cool: it's creating a pipeline made up of a transformer (it cleans the data) and the estimator itself—in this case logistic regression. When you fit the model to the data, it automatically runs the transformer first, then fits the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00004-8876cb30-4a60-4115-a191-56ee8a5838ca",
    "execution_millis": 57,
    "execution_start": 1603917607852,
    "output_cleared": false,
    "source_hash": "f3fdfdbf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(random_state=0)\n",
    ")\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-42dd11e2-e65e-4103-9266-683e2d4c7323",
    "tags": []
   },
   "source": [
    "We can then evaluate this model using the imported `accuracy_score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00005-7c15e872-98c2-45ab-9596-68ad19eced2b",
    "execution_millis": 0,
    "execution_start": 1603917648014,
    "output_cleared": false,
    "source_hash": "e42f493a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-ef52ba5f-bb47-4796-86c5-930f78663330",
    "tags": []
   },
   "source": [
    "sklearn has a bunch of tools to evaluate your model, including cross-validation. My model of it right now is a way of splitting the training and test data in such a way that it helps your model learn better. I don't have a formal definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00010-b8cb307a-b6f8-46d4-951f-f35e5392f15a",
    "execution_millis": 538,
    "execution_start": 1603919275678,
    "output_cleared": false,
    "source_hash": "45868a3a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples=1000, random_state=0) # this is cool! it generates a random regression problem\n",
    "lr = LinearRegression()\n",
    "\n",
    "result = cross_validate(lr, X, y)\n",
    "result['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-85da78fe-24cf-4544-ba8d-7735d15768e7",
    "tags": []
   },
   "source": [
    "Estimators have parameters—called hyper-parameters—that you can tune. It's not clear beforehand what these should be, since they depend on the data you're working with. sklearn has tools to find the best parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00012-22ec8204-1bbe-4060-803c-0f076d76f6f1",
    "execution_millis": 3795,
    "execution_start": 1603920273489,
    "output_cleared": false,
    "source_hash": "eaafcbe5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "param_distributions = {'n_estimators': randint(1, 5),\n",
    "                        'max_depth': randint(5, 10)}\n",
    "                \n",
    "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
    "                            n_iter=5,\n",
    "                            param_distributions=param_distributions,\n",
    "                            random_state=0)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "00013-c55dd4ea-a696-487e-a305-37c4aef606a9",
    "execution_millis": 45,
    "execution_start": 1603920279426,
    "output_cleared": false,
    "source_hash": "ab2a03e2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735363411343253"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-5efc0336-9c59-40e9-9cbb-d559cb8a2ac3",
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ab8f9f56-065b-4daa-a5ab-ee7a0763289e",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
